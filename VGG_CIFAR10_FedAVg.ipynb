{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='data',\n",
    "                                             train=True,\n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data',\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_clients_datasets(dataset, n = 10, IID = True):\n",
    "    if IID:\n",
    "        l = len(dataset)\n",
    "        length = [l // n] * (n - 1) + [l - l // n * (n - 1)]\n",
    "        return torch.utils.data.random_split(dataset, length)\n",
    "    else:\n",
    "        return [torch.utils.data.Subset(dataset, (torch.tensor(dataset.targets) == i).nonzero()) for i in range(n)]\n",
    "\n",
    "xxx = gen_clients_datasets(train_dataset, IID=False)\n",
    "for i in xxx[4]:\n",
    "    print(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/cifar-10-batches-py/batches.meta', 'rb') as file:\n",
    "    label_name = pickle.load(file, encoding='bytes')[b'label_names']\n",
    "# label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "fig = plt.figure()\n",
    "for i in range(n * n):\n",
    "    index = torch.randint(0, len(train_dataset), size=(1, )).item()\n",
    "    img, label = train_dataset[index]\n",
    "    fig.add_subplot(n, n, i + 1)\n",
    "    plt.title(label_name[label].decode('utf-8'))\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet\n",
    "![VGGNet](https://pytorch.org/assets/images/vgg.png)\n",
    "![vgg11](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_block(count, in_channel, out_channel):\n",
    "    block = []\n",
    "    for i in range(count):\n",
    "        block.append(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1))\n",
    "        block.append(nn.ReLU())\n",
    "        in_channel = out_channel\n",
    "    return block + [nn.MaxPool2d(kernel_size=2, stride=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16_arch = ((2, 64), (2, 128), (3, 256), (3, 512), (3, 512))  # VGG16Net\n",
    "VGG_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))  # VGG11Net\n",
    "\n",
    "in_channel = 3\n",
    "blocks = []\n",
    "\n",
    "for (count, out_channel) in VGG_arch:\n",
    "    blocks += VGG_block(count, in_channel, out_channel)\n",
    "    in_channel = out_channel\n",
    "\n",
    "blocks_out_channel = VGG_arch[-1][1] * (32 // 2 ** len(VGG_arch)) ** 2\n",
    "VGG11Net = nn.Sequential(\n",
    "    *blocks, nn.Flatten(),\n",
    "    nn.Linear(blocks_out_channel, 4096), nn.ReLU(), nn.Dropout(.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(.5),\n",
    "    nn.Linear(4096, 10),\n",
    ")\n",
    "\n",
    "print(f'on: {device}')\n",
    "VGG11Net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.randn(size=(1, 3, 32, 32)).to(device)\n",
    "for block in VGG11Net:\n",
    "    sample = block(sample)\n",
    "    print(block.__class__.__name__, '   \\t gives:', sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(x):\n",
    "    if isinstance(x, nn.Linear) or isinstance(x, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(x.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.zeros_(x.bias)\n",
    "        # x.bias.zero_()\n",
    "\n",
    "if input('load stored model? [y/n]') == 'y':\n",
    "    VGG11Net.load_state_dict(torch.load('VGG11Net_Fed.pth'))\n",
    "else:\n",
    "    VGG11Net.apply(init_weight)\n",
    "VGG11Net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multinomial(torch.ones((10,)), 4, replacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "num_epoch = 60\n",
    "\n",
    "lr = .01\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(dataloader, model):\n",
    "    hit, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = VGG11Net(x).softmax(dim=1).argmax(dim=1)\n",
    "            hit += (y_hat == y).sum()\n",
    "            total += y.size(0)\n",
    "        return hit / total\n",
    "\n",
    "x_epoch, y_loss, y_acctrain, y_acctest = [], [], [], []\n",
    "\n",
    "num_clients = 10\n",
    "client_epochs = 1\n",
    "IID = True\n",
    "clients = gen_clients_datasets(train_dataset ,num_clients, IID=IID)\n",
    "num_turn = 50\n",
    "clients_frac = .5\n",
    "client_batchsize = 10   # 0 for B = infinity\n",
    "\n",
    "def add_to_model(model_sum, model, ratio):\n",
    "    for i in range(len(model)):\n",
    "        if isinstance(model[i], nn.Linear) or isinstance(model[i], nn.Conv2d):\n",
    "            if model_sum[i] is None:\n",
    "                model_sum[i] = [model[i].weight.data * ratio, model[i].bias.data * ratio]\n",
    "            else:\n",
    "                model_sum[i][0] += model[i].weight.data * ratio\n",
    "                model_sum[i][1] += model[i].bias.data * ratio\n",
    "        \n",
    "for turn in trange(num_turn, desc='turn'):\n",
    "    model_sum = [None for i in range(len(VGG11Net))]\n",
    "    client_size = int(num_clients * clients_frac)\n",
    "    idxs = torch.multinomial(torch.ones(num_clients,), client_size, replacement=False)\n",
    "    n_total = sum([len(clients[idx]) for idx in idxs])\n",
    "    for idx in tqdm(idxs, desc=f'{client_size} chosen clients'):\n",
    "        client_train_loader = DataLoader(clients[idx], batch_size=client_batchsize if client_batchsize else len(clients[idx]))\n",
    "        client_model = deepcopy(VGG11Net)\n",
    "        optimizer = torch.optim.SGD(client_model.parameters(), lr=lr, weight_decay=2e-3)\n",
    "        for epoch in range(client_epochs):\n",
    "            for x, y in client_train_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                y_hat = client_model(x).softmax(dim=1)\n",
    "                l = loss(y_hat, y)\n",
    "                l.backward()\n",
    "                optimizer.step()\n",
    "        add_to_model(model_sum, client_model, len(clients[idx]) / n_total)\n",
    "    for i, layer in enumerate(VGG11Net):\n",
    "        if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "            layer.weight.data, layer.bias.data = model_sum[i]\n",
    "\n",
    "    print(accuracy(test_loader, VGG11Net))\n",
    "\n",
    "import requests\n",
    "requests.get('https://maker.ifttt.com/trigger/model_down/with/key/c4J6dG9XEDH4pEFnecPmMk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_epoch, y_loss, '.', label='loss')\n",
    "plt.plot(x_epoch, y_acctest, 'r-', label='test acc')\n",
    "plt.plot(x_epoch, y_acctrain, 'g-', label='train acc')\n",
    "plt.xlim(1,num_epoch)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = 2,4\n",
    "for _ in range(3): # no. images\n",
    "    fig = plt.figure()\n",
    "    for i in range(n * m):\n",
    "        index = torch.randint(0, len(test_dataset), size=(1, )).item()\n",
    "        img, label = test_dataset[index]\n",
    "        fig.add_subplot(n, m, i + 1)\n",
    "        pred = VGG11Net(img.to(device).reshape(1,3,32,32)).softmax(dim=1).argmax(dim=1)\n",
    "        tolb = lambda l : label_name[l].decode('utf-8')\n",
    "        plt.title(tolb(label) + '\\n' + f'({tolb(pred)})')\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7bd1401f6e8c4ab44e1da7ba272d605c8262707eff472ce2e183b5034fee45ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
